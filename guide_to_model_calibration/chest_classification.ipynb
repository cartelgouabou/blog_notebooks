{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Exploration\n",
    "# Read csv file containing training data\n",
    "train_df = pd.read_csv(\"data/nih/train-small.csv\")\n",
    "\n",
    "# Print first 5 rows\n",
    "print(f'There are {train_df.shape[0]} rows and {train_df.shape[1]} columns in this data frame')\n",
    "train_df.head()\n",
    "\n",
    "# 2. Image preprocessing\n",
    "# Define image size and batch size\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Data generator with augmentation for training data\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generator for validation data\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Patient overlap and data leakage\n",
    "# Assuming train_df contains columns 'PatientID' and 'ImagePath'\n",
    "train_df['PatientID'] = train_df['ImagePath'].apply(lambda x: x.split('_')[0])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['PatientID'])\n",
    "\n",
    "# Ensure no patient overlap between training and validation sets\n",
    "print(f'Number of unique patients in training set: {train_df[\"PatientID\"].nunique()}')\n",
    "print(f'Number of unique patients in validation set: {val_df[\"PatientID\"].nunique()}')\n",
    "print(f'Patient overlap: {set(train_df[\"PatientID\"]).intersection(set(val_df[\"PatientID\"]))}')\n",
    "\n",
    "# 4. Training pretrained CNN\n",
    "# Load the DenseNet121 model pre-trained on ImageNet\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data generators\n",
    "train_generator = datagen_train.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='FindingLabel',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = datagen_val.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='ImagePath',\n",
    "    y_col='FindingLabel',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10)\n",
    "\n",
    "# 5. Generate prediction metrics (AUC, balanced accuracy, brier score, ECE and plot curve)\n",
    "# Predict on validation set\n",
    "val_generator.reset()\n",
    "preds = model.predict(val_generator)\n",
    "y_true = val_df['FindingLabel'].values\n",
    "\n",
    "# Calculate AUC and balanced accuracy\n",
    "auc = roc_auc_score(y_true, preds)\n",
    "balanced_acc = balanced_accuracy_score(y_true, preds.round())\n",
    "\n",
    "# Calculate Brier score\n",
    "brier = brier_score_loss(y_true, preds)\n",
    "\n",
    "# Calculate ECE\n",
    "prob_true, prob_pred = calibration_curve(y_true, preds, n_bins=10)\n",
    "ece = np.mean(np.abs(prob_true - prob_pred))\n",
    "\n",
    "# Plot calibration curve\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=1, label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration plot')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'AUC: {auc}')\n",
    "print(f'Balanced Accuracy: {balanced_acc}')\n",
    "print(f'Brier Score: {brier}')\n",
    "print(f'Expected Calibration Error (ECE): {ece}')\n",
    "\n",
    "# 6. Enhance model calibration with Platt Scaling\n",
    "# Fit logistic regression for Platt Scaling\n",
    "platt_model = LogisticRegression()\n",
    "platt_model.fit(preds.reshape(-1, 1), y_true)\n",
    "\n",
    "# Transform predictions\n",
    "platt_preds = platt_model.predict_proba(preds.reshape(-1, 1))[:, 1]\n",
    "\n",
    "# 7. Generate again prediction metrics\n",
    "# Calculate new metrics after Platt Scaling\n",
    "auc_platt = roc_auc_score(y_true, platt_preds)\n",
    "balanced_acc_platt = balanced_accuracy_score(y_true, platt_preds.round())\n",
    "brier_platt = brier_score_loss(y_true, platt_preds)\n",
    "prob_true_platt, prob_pred_platt = calibration_curve(y_true, platt_preds, n_bins=10)\n",
    "ece_platt = np.mean(np.abs(prob_true_platt - prob_pred_platt))\n",
    "\n",
    "# Plot calibration curve after Platt Scaling\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(prob_pred_platt, prob_true_platt, marker='o', linewidth=1, label='Platt Scaled Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration plot after Platt Scaling')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'AUC after Platt Scaling: {auc_platt}')\n",
    "print(f'Balanced Accuracy after Platt Scaling: {balanced_acc_platt}')\n",
    "print(f'Brier Score after Platt Scaling: {brier_platt}')\n",
    "print(f'Expected Calibration Error (ECE) after Platt Scaling: {ece_platt}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
